{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6ba7dd",
   "metadata": {},
   "source": [
    "## 训练循环与双重早停策略\n",
    "\n",
    "本模块实现了 PyTorch 训练与验证的标准 Epoch 循环，并集成了一种鲁棒的**双重早停 (Early Stopping)** 机制，以优化收敛和防止过拟合。\n",
    "\n",
    "### 核心流程\n",
    "\n",
    "1.  **数据预处理：**\n",
    "    * 训练和验证阶段均对输入张量进行了转置 (`permute`)，从 `(B, H, W, C)` 转换为 PyTorch 标准的 `(B, C, H, W)` 格式。\n",
    "    * 仅提取前三个通道 (`inputs[:, :3, :, :]`)，表明输入图像可能为四通道或更高通道，但模型仅使用 RGB（或前三通道）。\n",
    "2.  **优化与调度：**\n",
    "    * 在**每个批次 (Batch)** 训练结束后，调用 `optimizer.step()` 更新参数，并调用 **`scheduler.step()`** 更新学习率（与 OneCycleLR 策略匹配）。\n",
    "3.  **性能评估：**\n",
    "    * 在每个 Epoch 结束后，计算并打印训练损失/准确率和验证损失/准确率。\n",
    "\n",
    "### 双重早停机制\n",
    "\n",
    "模型训练的停止条件由两个策略独立控制：\n",
    "\n",
    "| 策略 | 触发条件 | 效果 |\n",
    "| :--- | :--- | :--- |\n",
    "| **策略 1: 绝对损失阈值** | 验证损失 (`val_epoch_loss`) **$\\le$ 预设阈值** (`BEST_LOSS_THRESHOLD=0.01`) | **强制停止**。一旦损失达到极佳水平，立即保存模型并结束训练。 |\n",
    "| **策略 2: 基于 Patience** | 连续 `patience` (40) 个 Epoch 验证损失未改善。 | **标准早停**。在等待期后停止训练，防止过拟合，并保存迄今为止**最佳**损失的模型。 |\n",
    "\n",
    "**模型保存：** 模型权重在以下两种情况被保存为 `\"best_model.pth\"`：\n",
    "1. 策略 1 触发（达到绝对阈值）。\n",
    "2. 策略 2 中，当前验证损失打破历史最低记录 (`best_val_loss`) 时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8574376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用的前置条件\n",
    "patience = 40 # 连续10个epoch验证损失没有改善就停止\n",
    "best_val_loss = float('inf') # 初始最佳验证损失设置为无穷大\n",
    "BEST_LOSS_THRESHOLD = 0.01 # 新增的停止阈值\n",
    "epochs_no_improve = 0 # 记录没有改善的epoch数量\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.permute(0, 3, 1, 2) # 转置为 (batch_size, channels, height, width)，调整输入通道顺序\n",
    "        inputs = inputs[:, :3, :, :] # 只取前三通道\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新参数\n",
    "        scheduler.step() # 调度器更新学习率\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.permute(0, 3, 1, 2) # 转置为 (batch_size, channels, height, width)，调整输入通道顺序\n",
    "            inputs = inputs[:, :3, :, :] # 只取前三通道\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    val_epoch_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 策略 1: 检查是否达到预设的最低损失阈值\n",
    "    if val_epoch_loss <= BEST_LOSS_THRESHOLD:\n",
    "        print(f\"\\n✨ 验证损失 {val_epoch_loss:.4f} 达到或低于阈值 {BEST_LOSS_THRESHOLD}，停止训练。\")\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"模型已保存。\")\n",
    "        break\n",
    "        \n",
    "    # 策略 2: 标准的基于 patience 的早停\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        epochs_no_improve = 0\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"验证损失降低，保存最佳模型。\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"验证损失未改善，耐心计数: {epochs_no_improve}/{patience}\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"\\n连续 {patience} 个epoch验证损失没有改善，停止训练。\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
